{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align=\"center\">ANÁLISIS DE ALGORITMOS</h1>\n",
    "\n",
    "<h1 align=\"center\">Sesión08: Algoritmos probabilistas</h1>\n",
    "\n",
    "<h1 align=\"center\">MEDELLÍN - COLOMBIA </h1>\n",
    "\n",
    "<h1 align=\"center\">2021 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/Analisis_de_Algoritmos/blob/master/images/CC-BY.png?raw=true\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "***Docente:*** Carlos Alberto Álvarez Henao, I.C. D.Sc.\n",
    "\n",
    "***e-mail:*** carlosalvarezh@gmail.com\n",
    "\n",
    "***skype:*** carlos.alberto.alvarez.henao\n",
    "\n",
    "***Linkedin:*** https://www.linkedin.com/in/carlosalvarez5/\n",
    "\n",
    "***github:*** https://github.com/carlosalvarezh/Metodos_Numericos\n",
    "\n",
    "***Herramienta:*** [Jupyter](http://jupyter.org/)\n",
    "\n",
    "***Kernel:*** Python 3.8\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/towards-artificial-intelligence/monte-carlo-simulation-an-in-depth-tutorial-with-python-bcf6eb7856c8\n",
    "\n",
    "https://medium.com/free-code-camp/randomized-algorithms-part-1-d89986bb685b\n",
    "\n",
    "https://medium.com/search?q=monte%20carlo\n",
    "\n",
    "https://towardsdatascience.com/the-house-always-wins-monte-carlo-simulation-eb82787da2a3\n",
    "\n",
    "https://medium.com/free-code-camp/solve-the-unsolvable-with-monte-carlo-methods-294de03c80cd\n",
    "\n",
    "https://towardsdatascience.com/an-overview-of-monte-carlo-methods-675384eb1694\n",
    "\n",
    "https://towardsdatascience.com/monte-carlo-simulations-with-python-part-1-f5627b7d60b0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='TOC'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introducción\" data-toc-modified-id=\"Introducción-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introducción</a></span><ul class=\"toc-item\"><li><span><a href=\"#Una-historia-sobre-un-tesoro,-un-dragón,-un-computador,-un-elfo-y-un-doblón.\" data-toc-modified-id=\"Una-historia-sobre-un-tesoro,-un-dragón,-un-computador,-un-elfo-y-un-doblón.-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Una historia sobre un tesoro, un dragón, un computador, un elfo y un doblón.</a></span></li><li><span><a href=\"#¿Qué-hemos-aprendido?\" data-toc-modified-id=\"¿Qué-hemos-aprendido?-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>¿Qué hemos aprendido?</a></span></li><li><span><a href=\"#Característica-fundamental-de-un-algoritmo-probabilista:\" data-toc-modified-id=\"Característica-fundamental-de-un-algoritmo-probabilista:-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Característica fundamental de un algoritmo probabilista:</a></span></li><li><span><a href=\"#Diferencias-entre-algoritmos-deterministas,-análisis-probabilista-de-algoritmos-y-algoritmos-aleatorios\" data-toc-modified-id=\"Diferencias-entre-algoritmos-deterministas,-análisis-probabilista-de-algoritmos-y-algoritmos-aleatorios-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Diferencias entre algoritmos deterministas, análisis probabilista de algoritmos y algoritmos aleatorios</a></span><ul class=\"toc-item\"><li><span><a href=\"#Algoritmos-deterministas\" data-toc-modified-id=\"Algoritmos-deterministas-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Algoritmos deterministas</a></span></li><li><span><a href=\"#Análisis-probababilista-de-algoritmos\" data-toc-modified-id=\"Análisis-probababilista-de-algoritmos-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Análisis probababilista de algoritmos</a></span></li></ul></li><li><span><a href=\"#Un-comentario-sobre-“el-azar”-y-“la-incertidumbre”:\" data-toc-modified-id=\"Un-comentario-sobre-“el-azar”-y-“la-incertidumbre”:-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Un comentario sobre “el azar” y “la incertidumbre”:</a></span></li><li><span><a href=\"#Ejemplo-de-comportamiento-de-los-distintos-tipos-ante-un-mismo-problema\" data-toc-modified-id=\"Ejemplo-de-comportamiento-de-los-distintos-tipos-ante-un-mismo-problema-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Ejemplo de comportamiento de los distintos tipos ante un mismo problema</a></span></li></ul></li><li><span><a href=\"#Algoritmos-probabilistas-numéricos\" data-toc-modified-id=\"Algoritmos-probabilistas-numéricos-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Algoritmos probabilistas numéricos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Estimación-aproximada-de-$\\pi$:\" data-toc-modified-id=\"Estimación-aproximada-de-$\\pi$:-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Estimación aproximada de $\\pi$:</a></span></li><li><span><a href=\"#Integración-probabilista\" data-toc-modified-id=\"Integración-probabilista-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Integración probabilista</a></span></li><li><span><a href=\"#Análisis-de-la-convergencia:\" data-toc-modified-id=\"Análisis-de-la-convergencia:-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Análisis de la convergencia:</a></span></li><li><span><a href=\"#Algoritmos-de-Monte-Carlo\" data-toc-modified-id=\"Algoritmos-de-Monte-Carlo-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Algoritmos de Monte Carlo</a></span></li></ul></li><li><span><a href=\"#Ejemplos-y-desafíos\" data-toc-modified-id=\"Ejemplos-y-desafíos-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Ejemplos y desafíos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Verificación-de-un-producto-matricial\" data-toc-modified-id=\"Verificación-de-un-producto-matricial-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Verificación de un producto matricial</a></span></li><li><span><a href=\"#¿Podemos-hacerlo-más-rápido?\" data-toc-modified-id=\"¿Podemos-hacerlo-más-rápido?-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>¿Podemos hacerlo más rápido?</a></span></li><li><span><a href=\"#Comprobación-de-primalidad.\" data-toc-modified-id=\"Comprobación-de-primalidad.-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Comprobación de primalidad.</a></span></li><li><span><a href=\"#Cuántos-Primos-están-en-P\" data-toc-modified-id=\"Cuántos-Primos-están-en-P-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Cuántos Primos están en P</a></span></li><li><span><a href=\"#Clave-pública-y-primalidad\" data-toc-modified-id=\"Clave-pública-y-primalidad-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Clave pública y primalidad</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Analisis_de_Algoritmos/blob/master/images/Random.PNG?raw=true\" width=\"500\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://medium.com/free-code-camp/randomized-algorithms-part-1-d89986bb685b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos aleatorios o probabilistas (*randomized algorithms*) son muy importantes en el campo de la informática teórica, así como en las aplicaciones del mundo real. Para muchos problemas, para obtener una respuesta determinista, una función que siempre devuelve la misma respuesta dada la misma entrada es computacionalmente costosa y no se puede resolver en tiempo polinomial.\n",
    "\n",
    "Cuando introducimos algo de aleatoriedad junto con la entrada, esperamos tener una complejidad de tiempo más eficiente. O esperamos tener una proporción de la solución óptima con un buen límite superior en el número de iteraciones que se necesitarán para obtener esa solución.\n",
    "\n",
    "Estos algoritmos son a menudo triviales de idear. Pero es mucho más complejo analizar y probar el tiempo de ejecución / corrección. Vale la pena señalar que existe una diferencia entre el análisis probabilístico y el análisis de algoritmos aleatorios. En el análisis probabilístico le damos al algoritmo una entrada que se supone que proviene de una distribución de probabilidad. Mientras que en el algoritmo aleatorio agregamos un número aleatorio a la entrada. Las siguientes imágenes deberían mostrar la distinción. Las imágenes son de diapositivas de conferencias de Stanford."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una historia sobre un tesoro, un dragón, un computador, un elfo y un doblón."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En $A$ o $B$ hay un tesoro de $x$ lingotes de oro pero no sé si está en $A$ o $B$. Un dragón visita cada noche el tesoro llevándose $y$ lingotes. Sé que si permanezco $4$ días más en $O$ con mi computador resolveré el misterio. Un elfo me ofrece un trato: Me da la solución ahora si le pago el equivalente a la cantidad que se llevaría el dragón en $3$ noches.\n",
    "\n",
    "***¿Qué debo hacer?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Analisis_de_Algoritmos/blob/master/images/Isla01.png?raw=true\" width=\"100\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Si me quedo $4$ días más en $O$ hasta resolver el misterio, podré llegar al tesoro en $9$ días, y obtener $x-9y$ lingotes.\n",
    "\n",
    "\n",
    "- Si acepto el trato con el elfo, llego al tesoro en $5$ días, encuentro allí $x-5y$ lingotes de los cuales debo pagar $3y$ al elfo, y obtengo $x-8y$ lingotes.\n",
    "\n",
    "Es mejor aceptar el trato pero…\n",
    "\n",
    "… ¡hay una solución mejor!\n",
    "\n",
    "¿Cuál?\n",
    "\n",
    "¡Usar el doblón que me queda en el bolsillo! Lo lanzo al aire para decidir a qué lugar voy primero ($A$ o $B$).\n",
    "\n",
    "- Si acierto a ir en primer lugar al sitio adecuado, obtengo $x-5y$ lingotes.\n",
    "\n",
    "\n",
    "- Si no acierto, voy al otro sitio después y me conformo con $x-10y$ lingotes.\n",
    "\n",
    "\n",
    "El beneficio medio esperado es $x-7.5y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué hemos aprendido?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- En algunos algoritmos en los que aparece una decisión, es preferible a veces elegir aleatoriamente antes que perder tiempo calculando qué alternativa es la mejor.\n",
    "\n",
    "\n",
    "- Esto ocurre si el tiempo requerido para determinar la elección óptima es demasiado frente al promedio obtenido tomando la decisión al azar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Característica fundamental de un algoritmo probabilista:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- el mismo algoritmo puede comportarse de distinta forma aplicado a los mismos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferencias entre algoritmos deterministas, análisis probabilista de algoritmos y algoritmos aleatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Analisis_de_Algoritmos/blob/master/images/DeterministicAlgorithms.PNG?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Analisis_de_Algoritmos/blob/master/images/ProbabilisticAnalisysAlgorithms.PNG?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Analisis_de_Algoritmos/blob/master/images/RandomizedAlgorithms013.PNG?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "http://theory.stanford.edu/people/pragh/amstalk.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algoritmos deterministas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El objetivo en el análisis de los algoritmos deterministas es demostrar que el algoritmo resuelve el problema correctamente (siempre) y rápidamente (por lo general, el número de pasos debe ser polinomial en el tamaño de la entrada). \n",
    "\n",
    "A un algoritmo determinista nunca se le permite que no termine: hacer una división por $0$, entrar en un bucle infinito, etc. Si existe más de una solución para unos datos dados, un algoritmo determinista siempre encuentra la misma solución (a no ser que se programe para encontrar varias o todas). No se le permite que calcule una solución incorrecta para ningún dato.\n",
    "\n",
    "El análisis de la eficiencia de un algoritmo determinista es, a veces, difícil.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis probababilista de algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En los algoritmos probabilistas se asume que los datos de entrada provienen de una distribución de probabilidad. A un algoritmo probabilista se le puede permitir equivocarse, siempre que eso ocurra con una probabiliad muy pequeña para datos cualesquiera. Si ocurre, se aborta el algoritmo y se repite su ejecución con los mismos datos de entrada. Repitiendo la ejecución un número suficiente de veces para el mismo dato, puede aumentarse tanto como se quiera el grado de confianza en obtener la solución correcta. Un algoritmo probabilista puede encontrar soluciones diferentes ejecutándose varias veces con los mismos datos.\n",
    "\n",
    "El análisis de los algoritmos probabilistas es, a menudo, muy difícil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un comentario sobre “el azar” y “la incertidumbre”:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Como se indicó arriba, a un algoritmo probabilista se le puede permitir calcular una solución equivocada, con una probabilidad pequeña. Un algoritmo determinista que tarde mucho tiempo en obtener la solución puede sufrir errores provocados por fallos del hardware y obtener una solución equivocada. Es decir, el algoritmo determinista tampoco garantiza siempre la certeza de la solución y además es más lento.\n",
    "\n",
    "Más aún, hay problemas para los que no se conoce ningún algoritmo (determinista ni probabilista) que dé la solución con certeza y en un tiempo razonable (por ejemplo, la duración de la vida del programador, o de la vida del universo…): Es mejor un algoritmo probabilista rápido que dé la solución correcta con una cierta probabilidad de error.\n",
    "\n",
    "\n",
    "***Ejemplo:*** decidir si un # de $1000$ cifras es primo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Analisis_de_Algoritmos/blob/master/images/Algoritmos_Probabilistas_01.png?raw=true\" width=\"350\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de comportamiento de los distintos tipos ante un mismo problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "“¿*Cuándo descubrió América Cristobal Colón*?”\n",
    "\n",
    "\n",
    "- Algoritmo numérico ejecutado cinco veces:\n",
    "\n",
    "  - “Entre 1490 y 1500.”\n",
    "  - “Entre 1485 y 1495.”\n",
    "  - “Entre 1491 y 1501.”\n",
    "  - “Entre 1480 y 1490.”\n",
    "  - “Entre 1489 y 1499.”\n",
    "\n",
    "Aparentemente, la probabilidad de dar un intervalo erroneo es del $20\\%$ ($1$ de cada $5$). Dando más tiempo a la ejecución se podría reducir esa probabilidad o reducir la anchura del intervalo (a menos de $11$ años)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Algoritmo de *Monte Carlo* ejecutado diez veces:\n",
    "\n",
    "$1492$, $1492$, $1492$, $1491$, $1492$, $1492$, $357 \\text{A.C.}$, $1492$, $1492$, $1492$.\n",
    "\n",
    "De nuevo un $20\\%$ de error. Ese porcentaje puede reducirse dando más tiempo para la ejecución. Las respuestas incorrectas pueden ser próximas a la correcta o completamente desviadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Algoritmo de Las Vegas ejecutado diez veces: \n",
    "\n",
    "$1492$, $1492$, $\\text{¡Perdón!}$, $1492$, $1492$, $1492$, $1492$, $1492$, $\\text{¡Perdón!}$, $1492$.\n",
    "\n",
    "El algoritmo nunca da una respuesta incorrecta. El algoritmo falla con una cierta probabilidad ($20\\%$ en este caso)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algoritmos probabilistas numéricos\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Primeros en aparecer: SGM (Stochastic Galerkin Method), clave “Monte Carlo”\n",
    "\n",
    "\n",
    "Un ejemplo ya conocido:\n",
    "\n",
    "- Simulación de un sistema de espera (cola) \n",
    "\n",
    "  - Estimar el tiempo medio de espera en el sistema.\n",
    "  \n",
    "  - En muchos casos la solución exacta no es posible.\n",
    "\n",
    "\n",
    "- La solución obtenida es siempre aproximada pero su precisión esperada mejora aumentando el tiempo de ejecución.\n",
    "\n",
    "\n",
    "- Normalmente, el error es inversamente proporcional a la raíz cuadrada del esfuerzo invertido en el cálculo\n",
    "\n",
    "  - Se necesita cien veces más de trabajo para obtener una cifra más de precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimación aproximada de $\\pi$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tiramos $n$ dardos sobre un cuadrado y contamos el número $k$ de los que caen en un círculo de radio unitario inscrito en el cuadrado.\n",
    "\n",
    "¿Cuál es la proporción media de dardos en el interior del círculo?:\n",
    "\n",
    "- Área del cuadrado: $A_{cuadrado}=r^2$\n",
    "\n",
    "- Área del Sector: $A_{sector}=\\frac{1}{4}\\pi r^2$\n",
    "\n",
    "dividiendo el área del círculo por el área del sector, se tiene: $\\frac{A_{sector}}{A_{cuadrado}}=\\frac{\\pi r^2}{4 r^2}=\\frac{\\pi}{4}$\n",
    "\n",
    "Si realizamos la división del número total de puntos que tenemos dentro del círculo respecto al número total de puntos que se han señalado en toda la área del cuadrado, tendremos una aproximación del valor de $\\pi$.\n",
    "\n",
    "$$\\frac{\\text{puntos dentro del círculo}}{\\text{puntos totales}}=\\frac{k}{n}\\approx \\frac{\\pi}{4}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Ejemplo: Aproximando el valor de pi - área de un círculo de\n",
    "# radio = 1.\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def mc_pi_aprox(N=10):\n",
    "    plt.figure(figsize=(8,8))  # tamaño de la figura\n",
    "    x, y = np.random.uniform(-1, 1, size=(2, N))\n",
    "    interior = (x**2 + y**2) <= 1\n",
    "    pi = interior.sum() * 4 / N\n",
    "    error = abs((pi - np.pi) / pi) * 100\n",
    "    exterior = np.invert(interior)\n",
    "    plt.plot(x[interior], y[interior], 'b.')\n",
    "    plt.plot(x[exterior], y[exterior], 'r.')\n",
    "    plt.plot(0, 0, label='$\\hat \\pi$ = {:4.4f}\\nerror = {:4.4f}%'\n",
    "             .format(pi,error), alpha=0)\n",
    "    plt.axis('square')\n",
    "    plt.legend(frameon=True, framealpha=0.9, fontsize=16)\n",
    "\n",
    "mc_pi_aprox()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integración probabilista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***Problema:*** Calcular $\\int_a^b f(x)dx$, donde $f(x)$ es una función continua y $a\\leq b$.\n",
    "\n",
    "Un posible algoritmo puede ser:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "función int_prob(f:función;n:entero; a,b:real)\n",
    "devuelve real\n",
    "{Algoritmo probabilista que estima la integral definida entre a y b generando n valores aleatorios xi en [a,b), haciendo la media de los f(xi) multiplicando el resultado por (b-a).\n",
    "Se utiliza la función uniforme(u,v) que genera un número pseudo-aleatorio uniformemente distribuido en [u,v).}\n",
    "\n",
    "variables suma,x:real; i:entero\n",
    "\n",
    "principio\n",
    "    suma:=0.0;\n",
    "    para i:=1 hasta n hacer:\n",
    "        x:=uniforme(a,b);\n",
    "        suma:=suma+f(x)\n",
    "    fin para;\n",
    "    devuelve (b-a)*(suma/n)\n",
    "fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def integral_prob(n, a, b):\n",
    "    sumap = 0\n",
    "    for i in range(n):\n",
    "        x = np.random.uniform(a,b)\n",
    "        sumap += f(x)\n",
    "    return (b-a)*sumap/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 4*(1-x**2)**0.5\n",
    "    #return x**3-5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Versión determinista:\n",
    "\n",
    "función int_det(f:función;n:entero; a,b:real)\n",
    "devuelve real\n",
    "\n",
    "principio\n",
    "    suma:=0.0;\n",
    "    delta = (b-a)/n\n",
    "    x = a + delta/2\n",
    "    para i:=1 hasta n hacer:\n",
    "        suma:=suma+f(x)\n",
    "        x:=x+delta;\n",
    "    fpara;\n",
    "    devuelve suma * delta\n",
    "fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def integral_det(n, a, b):\n",
    "    sumad = 0\n",
    "    delta = (b-a)/n\n",
    "    x = a + delta/2\n",
    "    for i in range(n):\n",
    "        sumad += f(x)\n",
    "        x = x + delta\n",
    "    return sumad * delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 100\n",
    "a = 0\n",
    "b = 1\n",
    "\n",
    "integralprob = integral_prob(n,a,b)\n",
    "print(\"Valor integral método probabilista\", integralprob)\n",
    "\n",
    "errorp = np.abs(np.pi-integralprob)/np.pi\n",
    "print(\"error prob.: \", errorp)\n",
    "\n",
    "integraldet = integral_det(n,a,b)\n",
    "print(\"Valor integral método determinista\",integraldet)\n",
    "\n",
    "errordet = np.abs(np.pi-integraldet)/np.pi\n",
    "print(\"error determ.: \", errordet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de la convergencia:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- La varianza del estimador calculado por la función anterior es inversamente proporcional al número n de muestras generadas y que la distribución del estimador es aproximadamente normal, cuando $n$ es grande.\n",
    "\n",
    "\n",
    "- Por tanto, el error esperado es inversamente proporcional a $\\sqrt{n}$.\n",
    "\n",
    "  - 100 veces más de trabajo para obtener una cifra más de precisión\n",
    "  \n",
    "- En general, la versión determinista es más eficiente (menos iteraciones para obtener precisión similar).\n",
    "\n",
    "\n",
    "- Pero, para todo algoritmo determinista de integración puede construirse una función que “lo vuelve loco” (no así para la versión probabilista).\n",
    "\n",
    "\n",
    "  - Por ejemplo, para $f(x)=sin^2(10! \\pi x)$ toda llamada a `int_det(n,0,1)` con $1 \\leq n \\leq 100$ devuelve $0$, aunque el valor exacto es $0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.sin(3628800*np.pi*x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "a = 0\n",
    "b = 1\n",
    "\n",
    "integralprob = integral_prob(n,a,b)\n",
    "print(\"Valor integral método probabilista\", integralprob)\n",
    "\n",
    "errorp = np.abs(0.5-integralprob)/0.5\n",
    "print(\"error prob.: \", errorp)\n",
    "\n",
    "integraldet = integral_det(n,a,b)\n",
    "print(\"Valor integral método determinista\",integraldet)\n",
    "\n",
    "errordet = np.abs(0.5-integraldet)/0.5\n",
    "print(\"error determ.: \", errordet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Otra ventaja: cálculo de integrales múltiples.\n",
    "\n",
    "\n",
    "  - *Algoritmos deterministas:* para mantener la precisión, el coste crece   exponencialmente con la dimensión del espacio.\n",
    "  \n",
    "  - En la práctica, se usan algoritmos probabilistas para dimensión $4$ o mayor.\n",
    "  \n",
    "  - Existen técnicas híbridas (parcialmente sistemáticas y parcialmente probabilistas): *integración cuasi-probabilista*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Algoritmos de Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Se usan para problemas que necesitan una respuesta, como problemas de decisión.\n",
    "\n",
    "- No se está seguro que la respuesta obtenido sea la correcta: obtienen la respuesta correcta con una determinada probabilidad.\n",
    "\n",
    "\n",
    "-  Cuanto más tiempo se dedica a la ejecución, más probable es encontrar la respuesta correcta.\n",
    "\n",
    "\n",
    "- Para una probabilidad $0< \\text{p} < 1$, un $\\text{algoritmo de MonteCarlo}$ se dice *$\\text{p-correcto}$* si propociona soluciones correctas con una probabilidad no inferior a $p$.\n",
    "\n",
    "La característica más importante del método de MonteCarlos es que suele ser posible reducir arbitrariamente la probabilidad de error a costa de un ligero aumento del tiempo de cálculo (*amplificación de la ventaja estocástica*) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El $\\text{algoritmo de MonteCarlo}$ Crudo o Puro está fundamentado en la generación de números aleatorios por el método de *Transformación Inversa*, el cual se basa en las distribuciones acumuladas de frecuencias:\n",
    "\n",
    "Determinar la/s V.A. y sus distribuciones acumuladas(F)\n",
    "\n",
    "- Generar un número aleatorio uniforme $\\in [0,1)$.\n",
    "\n",
    "\n",
    "- Determinar el valor de la V.A. para el número aleatorio generado de acuerdo a las clases que tengamos.\n",
    "\n",
    "\n",
    "- Calcular media, desviación estándar error y realizar el histograma.\n",
    "\n",
    "\n",
    "- Analizar resultados para distintos tamaños de muestra. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Otra opción para trabajar con Monte Carlo, cuando la variable aleatoria no es directamente el resultado de la simulación o tenemos relaciones entre variables es la siguiente:\n",
    "\n",
    "- Diseñar el modelo lógico de decisión\n",
    "\n",
    "\n",
    "- Especificar distribuciones de probabilidad para las variables aleatorias relevantes.\n",
    "\n",
    "\n",
    "- Incluir posibles dependencias entre variables.\n",
    "\n",
    "\n",
    "- Muestrear valores de las variables aleatorias.\n",
    "\n",
    "\n",
    "- Calcular el resultado del modelo según los valores del muestreo (iteración) y registrar el resultado.\n",
    "\n",
    "\n",
    "- Repetir el proceso hasta tener una muestra estadísticamente representativa\n",
    "\n",
    "\n",
    "- Obtener la distribución de frecuencias del resultado de las iteraciones\n",
    "\n",
    "\n",
    "- Calcular media, desvío.\n",
    "\n",
    "\n",
    "- Analizar los resultados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Las principales características a tener en cuenta para la implementación o utilización del algoritmo son:\n",
    "\n",
    "\n",
    "- El sistema debe ser descrito por 1 o más funciones de distribución de probabilidad (fdp)\n",
    "\n",
    "\n",
    "- Generador de números aleatorios: como se generan los números aleatorios es importante para evitar que se produzca correlación entre los valores muestrales.\n",
    "\n",
    "\n",
    "- Establecer límites y reglas de muestreo para las fdp: conocemos que valores pueden adoptar las variables.\n",
    "\n",
    "\n",
    "- Definir Scoring: Cuando un valor aleatorio tiene o no sentido para el modelo a simular.\n",
    "\n",
    "\n",
    "- Estimación Error: Con que error trabajamos, cuanto error podemos aceptar para que una corrida sea válida?\n",
    "\n",
    "\n",
    "- Técnicas de reducción de varianza.\n",
    "\n",
    "\n",
    "- Paralelización y vectorización: En aplicaciones con muchas variables se estudia trabajar con varios procesadores paralelos para realizar la simulación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejemplos y desafíos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificación de un producto matricial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Problema: Dadas tres matrices $n\\times n$, $\\text{A, B, C}$, verificar si $\\text{C=AB}$\n",
    "\n",
    "***Solución trivial:*** hacer la multiplicación.\n",
    "\n",
    "- Algoritmo directo: coste $\\mathcal{O}(n^3)$.\n",
    "- Algoritmo de *Strassen* (Divide y vencerás): $\\mathcal{O}(n^{2.81})$.\n",
    "- Otros menos prácticos: $\\mathcal{O}(n^{2.373})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Podemos hacerlo más rápido?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[R. Freivalds: “Fast probabilistic algorithms”, Proceedings of the 8th Symposium on the Mathematical Foundations of Computer Science, Lecture Notes in Computer Science, vol. 74, Springer-Verlag, 1979.](https://link.springer.com/chapter/10.1007/3-540-09526-8_5 \"Fast probabilistic algorithms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobación de primalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Es el algoritmo de Monte Carlo más conocido: decidir si un número impar es primo o compuesto.\n",
    "\n",
    "\n",
    "- Ningún algoritmos determinista conocido puede responder en tiempo 'razonable' si el número es 'grande'\n",
    "\n",
    "\n",
    "- La utilización de números primos 'grandes' es fundamental en criptografía"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuántos Primos están en P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En $2002$ se publicó el *AKS primality test* (test de primalidad de *Agrawal–Kayal–Saxena*)\n",
    "\n",
    "- Es el primer test de primalidad que es general, tiempo polinómico, determinista e incondicional\n",
    "\n",
    "\n",
    "- Pero sigue siendo cierto que no se conocen algoritmos deterministas en tiempo razonable, ya que hoy en día la mejor cota conocida (mejora del *AKS*) es $\\mathcal{O}(n^6)$ (donde $n$ es el número de bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clave pública y primalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los primos son fundamentales en criptografía\n",
    " \n",
    "- ***Ejemplo:*** El protocolo de clave pública RSA permite codificar mensajes usando la clave pública y decodificar usando la clave privada (y firmar usando la clave privada y verificar usando la clave pública)\n",
    "\n",
    "\n",
    "- La seguridad del sistema RSA está (en parte) basada en que no es posible factorizar números grandes en tiempo razonable \n",
    "\n",
    "\n",
    "- Factorizar parece bastante más difícil que testear primalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[Volver a la Tabla de Contenido](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
